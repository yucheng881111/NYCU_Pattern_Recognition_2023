{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9231d737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:40.545300Z",
     "iopub.status.busy": "2023-05-02T13:35:40.544880Z",
     "iopub.status.idle": "2023-05-02T13:35:43.638226Z",
     "shell.execute_reply": "2023-05-02T13:35:43.636890Z"
    },
    "papermill": {
     "duration": 3.101989,
     "end_time": "2023-05-02T13:35:43.641403",
     "exception": false,
     "start_time": "2023-05-02T13:35:40.539414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df32331f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:43.670351Z",
     "iopub.status.busy": "2023-05-02T13:35:43.669920Z",
     "iopub.status.idle": "2023-05-02T13:35:43.676759Z",
     "shell.execute_reply": "2023-05-02T13:35:43.675413Z"
    },
    "papermill": {
     "duration": 0.015331,
     "end_time": "2023-05-02T13:35:43.679636",
     "exception": false,
     "start_time": "2023-05-02T13:35:43.664305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "alphabets = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "alphabets2index = {alphabet:i for i, alphabet in enumerate(alphabets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f28c646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:43.689981Z",
     "iopub.status.busy": "2023-05-02T13:35:43.688756Z",
     "iopub.status.idle": "2023-05-02T13:35:43.698376Z",
     "shell.execute_reply": "2023-05-02T13:35:43.697256Z"
    },
    "papermill": {
     "duration": 0.017827,
     "end_time": "2023-05-02T13:35:43.701316",
     "exception": false,
     "start_time": "2023-05-02T13:35:43.683489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False):\n",
    "        self.data = data\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        path = f\"{self.root}/{filename}\"\n",
    "        img = Image.open(path)\n",
    "        # img = cv2.resize(img, (32, 32))\n",
    "        # img = np.mean(img, axis=2)\n",
    "        preprocess = transforms.Compose([\n",
    "            #transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        input_tensor = preprocess(img)\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        \n",
    "        if self.return_filename:\n",
    "            return input_tensor, filename\n",
    "        else:\n",
    "            return input_tensor, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671383a0",
   "metadata": {},
   "source": [
    "# Model\n",
    "implement ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0241d66f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:43.711580Z",
     "iopub.status.busy": "2023-05-02T13:35:43.710438Z",
     "iopub.status.idle": "2023-05-02T13:35:43.719108Z",
     "shell.execute_reply": "2023-05-02T13:35:43.717803Z"
    },
    "papermill": {
     "duration": 0.016827,
     "end_time": "2023-05-02T13:35:43.722026",
     "exception": false,
     "start_time": "2023-05-02T13:35:43.705199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel,\n",
    "                      outchannel,\n",
    "                      kernel_size=3,\n",
    "                      stride=stride,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(outchannel, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel,\n",
    "                      outchannel,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(outchannel, track_running_stats=True))\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel,\n",
    "                          outchannel,\n",
    "                          kernel_size=1,\n",
    "                          stride=stride,\n",
    "                          bias=False),\n",
    "                nn.BatchNorm2d(outchannel, track_running_stats=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet34_1(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=62):\n",
    "        super(ResNet34_1, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # res18 2 2 2 2\n",
    "        # res34 3 4 6 3\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64, 3, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 4, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 6, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 3, stride=2)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(512, num_classes)\n",
    "        #self.fc2 = nn.Linear(512, num_classes)\n",
    "        #self.fc3 = nn.Linear(512, num_classes)\n",
    "        #self.fc4 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)  # strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = nn.AdaptiveAvgPool2d(1)(x)\n",
    "        x = x.view(-1, 512)\n",
    "        x = self.drop(x)\n",
    "        y1 = self.fc1(x)\n",
    "        #y2 = self.fc2(x)\n",
    "        #y3 = self.fc3(x)\n",
    "        #y4 = self.fc4(x)\n",
    "        return y1\n",
    "    \n",
    "class ResNet34_2(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=62):\n",
    "        super(ResNet34_2, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # res18 2 2 2 2\n",
    "        # res34 3 4 6 3\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64, 3, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 4, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 6, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 3, stride=2)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(512, num_classes)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        #self.fc3 = nn.Linear(512, num_classes)\n",
    "        #self.fc4 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)  # strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = nn.AdaptiveAvgPool2d(1)(x)\n",
    "        x = x.view(-1, 512)\n",
    "        x = self.drop(x)\n",
    "        y1 = self.fc1(x)\n",
    "        y2 = self.fc2(x)\n",
    "        #y3 = self.fc3(x)\n",
    "        #y4 = self.fc4(x)\n",
    "        return y1, y2\n",
    "\n",
    "class ResNet34_3(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=62):\n",
    "        super(ResNet34_3, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # res18 2 2 2 2\n",
    "        # res34 3 4 6 3\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64, 3, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 4, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 6, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 3, stride=2)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(512, num_classes)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "        self.fc4 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)  # strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = nn.AdaptiveAvgPool2d(1)(x)\n",
    "        x = x.view(-1, 512)\n",
    "        x = self.drop(x)\n",
    "        y1 = self.fc1(x)\n",
    "        y2 = self.fc2(x)\n",
    "        y3 = self.fc3(x)\n",
    "        y4 = self.fc4(x)\n",
    "        return y1, y2, y3, y4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefba85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"dataset/train\"\n",
    "TEST_PATH = \"dataset/test\"\n",
    "# train_data_t1 = []\n",
    "# val_data_t1 = []\n",
    "# train_data_t2 = []\n",
    "# val_data_t2 = []\n",
    "# train_data_t3 = []\n",
    "# val_data_t3 = []\n",
    "\n",
    "# np.random.seed(0)\n",
    "# with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n",
    "#     for row in csv.reader(csvfile, delimiter=','):\n",
    "#         if row[0].startswith(\"task1\"):\n",
    "#             if np.random.random() < 0.8:\n",
    "#                 train_data_t1.append(row)\n",
    "#             else:\n",
    "#                 val_data_t1.append(row)\n",
    "        \n",
    "#         if row[0].startswith(\"task2\"):\n",
    "#             if np.random.random() < 0.8:\n",
    "#                 train_data_t2.append(row)\n",
    "#             else:\n",
    "#                 val_data_t2.append(row)\n",
    "        \n",
    "#         if row[0].startswith(\"task3\"):\n",
    "#             if np.random.random() < 0.8:\n",
    "#                 train_data_t3.append(row)\n",
    "#             else:\n",
    "#                 val_data_t3.append(row)\n",
    "\n",
    "# print(len(train_data_t1))\n",
    "# print(len(val_data_t1))\n",
    "# print(len(train_data_t2))\n",
    "# print(len(val_data_t2))\n",
    "# print(len(train_data_t3))\n",
    "# print(len(val_data_t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4829873",
   "metadata": {},
   "source": [
    "# Task 1 Data Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2e402a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000\n",
      "41000\n"
     ]
    }
   ],
   "source": [
    "total_data_t1 = []\n",
    "with open(f'{TRAIN_PATH}/task1/output/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        if row[1].startswith(\"task1\"):\n",
    "            file_path = 'task1/output/' + row[1]\n",
    "            total_data_t1.append([file_path, row[2]])\n",
    "\n",
    "print(len(total_data_t1))\n",
    "\n",
    "with open(f'{TRAIN_PATH}/task1/gen/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        file_path = 'task1/gen/' + row[0]\n",
    "        total_data_t1.append([file_path, row[1]])\n",
    "\n",
    "print(len(total_data_t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ca3bd",
   "metadata": {},
   "source": [
    "# Task 2 Data Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78229aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000\n",
      "41000\n"
     ]
    }
   ],
   "source": [
    "total_data_t2 = []\n",
    "with open(f'{TRAIN_PATH}/task2/output/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        if row[1].startswith(\"task2\"):\n",
    "            file_path = 'task2/output/' + row[1]\n",
    "            total_data_t2.append([file_path, row[2]])\n",
    "\n",
    "print(len(total_data_t2))\n",
    "\n",
    "with open(f'{TRAIN_PATH}/task2/gen/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        file_path = 'task2/gen/' + row[0]\n",
    "        total_data_t2.append([file_path, row[1]])\n",
    "\n",
    "print(len(total_data_t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a22cde",
   "metadata": {},
   "source": [
    "# Task 3 Data Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c97f1be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000\n",
      "71000\n"
     ]
    }
   ],
   "source": [
    "total_data_t3 = []\n",
    "with open(f'{TRAIN_PATH}/task3/output/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        if row[1].startswith(\"task3\"):\n",
    "            file_path = 'task3/output/' + row[1]\n",
    "            total_data_t3.append([file_path, row[2]])\n",
    "\n",
    "print(len(total_data_t3))\n",
    "\n",
    "with open(f'{TRAIN_PATH}/task3/gen/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        file_path = 'task3/gen/' + row[0]\n",
    "        total_data_t3.append([file_path, row[1]])\n",
    "\n",
    "print(len(total_data_t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835a0803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41000\n",
      "41000\n",
      "71000\n",
      "\n",
      "43000\n",
      "43500\n",
      "75000\n",
      "\n",
      "34446\n",
      "8554\n",
      "34774\n",
      "8726\n",
      "59902\n",
      "15098\n"
     ]
    }
   ],
   "source": [
    "print(len(total_data_t1))\n",
    "print(len(total_data_t2))\n",
    "print(len(total_data_t3))\n",
    "print()\n",
    "\n",
    "with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        if row[0].startswith(\"task1\"):\n",
    "            total_data_t1.append(row)\n",
    "        \n",
    "        if row[0].startswith(\"task2\"):\n",
    "            total_data_t2.append(row)\n",
    "            \n",
    "        if row[0].startswith(\"task3\"):\n",
    "            total_data_t3.append(row)\n",
    "\n",
    "np.random.seed(0)\n",
    "train_data_t1 = []\n",
    "val_data_t1 = []\n",
    "train_data_t2 = []\n",
    "val_data_t2 = []\n",
    "train_data_t3 = []\n",
    "val_data_t3 = []\n",
    "\n",
    "print(len(total_data_t1))\n",
    "print(len(total_data_t2))\n",
    "print(len(total_data_t3))\n",
    "print()\n",
    "\n",
    "for i in range(len(total_data_t1)):\n",
    "    if np.random.random() < 0.8:\n",
    "        train_data_t1.append(total_data_t1[i])\n",
    "    else:\n",
    "        val_data_t1.append(total_data_t1[i])\n",
    "    \n",
    "for i in range(len(total_data_t2)):\n",
    "    if np.random.random() < 0.8:\n",
    "        train_data_t2.append(total_data_t2[i])\n",
    "    else:\n",
    "        val_data_t2.append(total_data_t2[i])\n",
    "    \n",
    "for i in range(len(total_data_t3)):\n",
    "    if np.random.random() < 0.8:\n",
    "        train_data_t3.append(total_data_t3[i])\n",
    "    else:\n",
    "        val_data_t3.append(total_data_t3[i])\n",
    "            \n",
    "\n",
    "print(len(train_data_t1))\n",
    "print(len(val_data_t1))\n",
    "print(len(train_data_t2))\n",
    "print(len(val_data_t2))\n",
    "print(len(train_data_t3))\n",
    "print(len(val_data_t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ffdf4",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4151ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:43.732379Z",
     "iopub.status.busy": "2023-05-02T13:35:43.731429Z",
     "iopub.status.idle": "2023-05-02T13:35:43.757472Z",
     "shell.execute_reply": "2023-05-02T13:35:43.756444Z"
    },
    "papermill": {
     "duration": 0.034602,
     "end_time": "2023-05-02T13:35:43.760542",
     "exception": false,
     "start_time": "2023-05-02T13:35:43.725940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "train_ds = TaskDataset(train_data_t1, root=TRAIN_PATH)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "val_ds = TaskDataset(val_data_t1, root=TRAIN_PATH)\n",
    "val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5254c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:43.770727Z",
     "iopub.status.busy": "2023-05-02T13:35:43.769493Z",
     "iopub.status.idle": "2023-05-02T13:36:43.805329Z",
     "shell.execute_reply": "2023-05-02T13:36:43.802741Z"
    },
    "papermill": {
     "duration": 60.043917,
     "end_time": "2023-05-02T13:36:43.808305",
     "exception": false,
     "start_time": "2023-05-02T13:35:43.764388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "loss: 1069.8796004652977\n",
      "accuracy (train): 0.4814492248737154\n",
      "accuracy (validation): 0.5176525602057517\n",
      "Epoch 2:\n",
      "loss: 177.52292348444462\n",
      "accuracy (train): 0.897549788074087\n",
      "accuracy (validation): 0.7718026654196867\n",
      "Epoch 3:\n",
      "loss: 131.54620141535997\n",
      "accuracy (train): 0.9231550833188179\n",
      "accuracy (validation): 0.8265139116202946\n",
      "Epoch 4:\n",
      "loss: 116.07230725884438\n",
      "accuracy (train): 0.9323578935144864\n",
      "accuracy (validation): 0.7408230067804535\n",
      "Epoch 5:\n",
      "loss: 105.79117263481021\n",
      "accuracy (train): 0.9404575277245544\n",
      "accuracy (validation): 0.7947159223754968\n",
      "Epoch 6:\n",
      "loss: 98.53949984163046\n",
      "accuracy (train): 0.9451605411368519\n",
      "accuracy (validation): 0.8235913023147066\n",
      "Epoch 7:\n",
      "loss: 90.15432460978627\n",
      "accuracy (train): 0.9485281309876328\n",
      "accuracy (validation): 0.787117138180968\n",
      "Epoch 8:\n",
      "loss: 86.66740427538753\n",
      "accuracy (train): 0.9509086686407711\n",
      "accuracy (validation): 0.8681318681318682\n",
      "Epoch 9:\n",
      "loss: 75.03829645551741\n",
      "accuracy (train): 0.9578760959182488\n",
      "accuracy (validation): 0.9303249941547814\n",
      "Epoch 10:\n",
      "loss: 78.07452552765608\n",
      "accuracy (train): 0.9561923009928583\n",
      "accuracy (validation): 0.9561608604161795\n",
      "Epoch 11:\n",
      "loss: 38.712582167238\n",
      "accuracy (train): 0.978052604075945\n",
      "accuracy (validation): 0.97509936871639\n",
      "Epoch 12:\n",
      "loss: 42.58072355017066\n",
      "accuracy (train): 0.9768042733553969\n",
      "accuracy (validation): 0.9693710544774374\n",
      "Epoch 13:\n",
      "loss: 41.711024296469986\n",
      "accuracy (train): 0.9784300063868083\n",
      "accuracy (validation): 0.9577975216273089\n",
      "Epoch 14:\n",
      "loss: 40.85399164352566\n",
      "accuracy (train): 0.9787203158567033\n",
      "accuracy (validation): 0.9741641337386018\n",
      "Epoch 15:\n",
      "loss: 40.49795072712004\n",
      "accuracy (train): 0.9797654299483249\n",
      "accuracy (validation): 0.9829319616553659\n",
      "Epoch 16:\n",
      "loss: 36.89517771266401\n",
      "accuracy (train): 0.9804331417290832\n",
      "accuracy (validation): 0.9743979424830489\n",
      "Epoch 17:\n",
      "loss: 36.021545640192926\n",
      "accuracy (train): 0.9819137200255472\n",
      "accuracy (validation): 0.9796586392331074\n",
      "Epoch 18:\n",
      "loss: 37.25844460912049\n",
      "accuracy (train): 0.9821169366544736\n",
      "accuracy (validation): 0.9768529342997428\n",
      "Epoch 19:\n",
      "loss: 34.64725745189935\n",
      "accuracy (train): 0.9837717006328747\n",
      "accuracy (validation): 0.9805938742108955\n",
      "Epoch 20:\n",
      "loss: 32.28478416893631\n",
      "accuracy (train): 0.984265226731696\n",
      "accuracy (validation): 0.9574468085106383\n",
      "Epoch 21:\n",
      "loss: 17.45191238168627\n",
      "accuracy (train): 0.9922197062068164\n",
      "accuracy (validation): 0.9886602758943185\n",
      "Epoch 22:\n",
      "loss: 15.71789914695546\n",
      "accuracy (train): 0.9936422226093015\n",
      "accuracy (validation): 0.9894786064998831\n",
      "Epoch 23:\n",
      "loss: 20.277555367909372\n",
      "accuracy (train): 0.992306799047785\n",
      "accuracy (validation): 0.9852700490998363\n",
      "Epoch 24:\n",
      "loss: 20.156811570283026\n",
      "accuracy (train): 0.9919293967369216\n",
      "accuracy (validation): 0.9900631283610007\n",
      "Epoch 25:\n",
      "loss: 18.46001417003572\n",
      "accuracy (train): 0.9925971085176798\n",
      "accuracy (validation): 0.9763853168108487\n",
      "Epoch 26:\n",
      "loss: 17.214912574738264\n",
      "accuracy (train): 0.9938164082912384\n",
      "accuracy (validation): 0.9781388823942015\n",
      "Epoch 27:\n",
      "loss: 19.295623638201505\n",
      "accuracy (train): 0.9926842013586483\n",
      "accuracy (validation): 0.9883095627776479\n",
      "Epoch 28:\n",
      "loss: 17.15243522077799\n",
      "accuracy (train): 0.9938744701852175\n",
      "accuracy (validation): 0.9865559971942951\n",
      "Epoch 29:\n",
      "loss: 17.06092758430168\n",
      "accuracy (train): 0.993671253556291\n",
      "accuracy (validation): 0.9843348141220482\n",
      "Epoch 30:\n",
      "loss: 17.90031311986968\n",
      "accuracy (train): 0.9929454798815537\n",
      "accuracy (validation): 0.9685527238718729\n",
      "Epoch 31:\n",
      "loss: 9.455345545895398\n",
      "accuracy (train): 0.9973872147709458\n",
      "accuracy (validation): 0.9929857376665887\n",
      "Epoch 32:\n",
      "loss: 9.648082632571459\n",
      "accuracy (train): 0.9974162457179353\n",
      "accuracy (validation): 0.9933364507832593\n",
      "Epoch 33:\n",
      "loss: 9.656332361977547\n",
      "accuracy (train): 0.9977355861348197\n",
      "accuracy (validation): 0.9928688332943653\n",
      "Epoch 34:\n",
      "loss: 8.954492928925902\n",
      "accuracy (train): 0.998171050339662\n",
      "accuracy (validation): 0.9904138414776713\n",
      "Epoch 35:\n",
      "loss: 9.192999043036252\n",
      "accuracy (train): 0.99828717412762\n",
      "accuracy (validation): 0.991933598316577\n",
      "Epoch 36:\n",
      "loss: 9.462756204418838\n",
      "accuracy (train): 0.998171050339662\n",
      "accuracy (validation): 0.9938040682721534\n",
      "Epoch 37:\n",
      "loss: 9.714452784508467\n",
      "accuracy (train): 0.9976484932938512\n",
      "accuracy (validation): 0.9888940846387655\n",
      "Epoch 38:\n",
      "loss: 9.757254003547132\n",
      "accuracy (train): 0.9976775242408408\n",
      "accuracy (validation): 0.9907645545943419\n",
      "Epoch 39:\n",
      "loss: 11.603230993729085\n",
      "accuracy (train): 0.9971839981420194\n",
      "accuracy (validation): 0.9915828851999064\n",
      "Epoch 40:\n",
      "loss: 8.10427524195984\n",
      "accuracy (train): 0.9982291122336411\n",
      "accuracy (validation): 0.9913490764554594\n",
      "Epoch 41:\n",
      "loss: 5.0620608404278755\n",
      "accuracy (train): 0.9996225976891366\n",
      "accuracy (validation): 0.994388590133271\n",
      "Epoch 42:\n",
      "loss: 5.729529423173517\n",
      "accuracy (train): 0.9995935667421472\n",
      "accuracy (validation): 0.9933364507832593\n",
      "Epoch 43:\n",
      "loss: 6.637198669835925\n",
      "accuracy (train): 0.9992742263252627\n",
      "accuracy (validation): 0.9928688332943653\n",
      "Epoch 44:\n",
      "loss: 5.877454454777762\n",
      "accuracy (train): 0.9995064739011786\n",
      "accuracy (validation): 0.9928688332943653\n",
      "Epoch 45:\n",
      "loss: 5.229439068585634\n",
      "accuracy (train): 0.9997967833710736\n",
      "accuracy (validation): 0.9942716857610474\n",
      "Epoch 46:\n",
      "loss: 7.520326329860836\n",
      "accuracy (train): 0.9990129478023573\n",
      "accuracy (validation): 0.994154781388824\n",
      "Epoch 47:\n",
      "loss: 5.878887091297656\n",
      "accuracy (train): 0.9993613191662312\n",
      "accuracy (validation): 0.9857376665887304\n",
      "Epoch 48:\n",
      "loss: 7.236059324815869\n",
      "accuracy (train): 0.9989548859083783\n",
      "accuracy (validation): 0.9934533551554828\n",
      "Epoch 49:\n",
      "loss: 6.0546416733413935\n",
      "accuracy (train): 0.9994774429541892\n",
      "accuracy (validation): 0.9932195464110358\n",
      "Epoch 50:\n",
      "loss: 6.518909632228315\n",
      "accuracy (train): 0.9991871334842942\n",
      "accuracy (validation): 0.9934533551554828\n",
      "task1 model saved\n"
     ]
    }
   ],
   "source": [
    "model = ResNet34_1(ResidualBlock).to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "totalEpoch = 50\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=6.5e-4)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "#optimizer = torch.optim.NAdam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=6.5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(totalEpoch):\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    total_loss = 0\n",
    "    train_sample_count = 0\n",
    "    train_correct_count = 0\n",
    "    model.train()\n",
    "    for image, label in train_dl:\n",
    "        image = image.to(device)\n",
    "        label = np.array([alphabets2index[l] for l in label])\n",
    "        label = torch.from_numpy(label)\n",
    "        label = label.to(device, dtype=torch.long)\n",
    "        \n",
    "        pred = model(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        total_loss += loss.item()\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        \n",
    "        train_sample_count += len(image)\n",
    "        train_correct_count += (label == pred).sum().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "        \n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    model.eval()\n",
    "    for image, label in val_dl:\n",
    "        image = image.to(device)\n",
    "        label = np.array([alphabets2index[l] for l in label])\n",
    "        label = torch.from_numpy(label)\n",
    "        label = label.to(device, dtype=torch.long)\n",
    "        \n",
    "        pred = model(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        \n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        \n",
    "        sample_count += len(image)\n",
    "        correct_count += (label == pred).sum().item()\n",
    "    \n",
    "    print(\"loss:\", total_loss)\n",
    "    print(\"accuracy (train):\", train_correct_count / train_sample_count)\n",
    "    print(\"accuracy (validation):\", correct_count / sample_count)\n",
    "\n",
    "torch.save(model.state_dict(), 'models/task1.pt')\n",
    "print('task1 model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1fb30",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74105fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "train_ds = TaskDataset(train_data_t2, root=TRAIN_PATH)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "val_ds = TaskDataset(val_data_t2, root=TRAIN_PATH)\n",
    "val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3947e642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "loss: 4262.9072341918945\n",
      "accuracy (train): 0.005032495542646805\n",
      "accuracy (validation): 0.052143020857208344\n",
      "Epoch 2:\n",
      "loss: 1159.7389877438545\n",
      "accuracy (train): 0.49462241904871457\n",
      "accuracy (validation): 0.7764153105661242\n",
      "Epoch 3:\n",
      "loss: 379.31259605288506\n",
      "accuracy (train): 0.8101167538965894\n",
      "accuracy (validation): 0.8072427228970892\n",
      "Epoch 4:\n",
      "loss: 287.90983855724335\n",
      "accuracy (train): 0.8544602289066544\n",
      "accuracy (validation): 0.7094888837955535\n",
      "Epoch 5:\n",
      "loss: 241.81379851698875\n",
      "accuracy (train): 0.8732961407948467\n",
      "accuracy (validation): 0.8713041485216594\n",
      "Epoch 6:\n",
      "loss: 225.64079688489437\n",
      "accuracy (train): 0.8833898889975269\n",
      "accuracy (validation): 0.9012147604859042\n",
      "Epoch 7:\n",
      "loss: 195.57864293456078\n",
      "accuracy (train): 0.8973370909300051\n",
      "accuracy (validation): 0.8788677515471006\n",
      "Epoch 8:\n",
      "loss: 191.6329801082611\n",
      "accuracy (train): 0.9003565882555933\n",
      "accuracy (validation): 0.9069447627779051\n",
      "Epoch 9:\n",
      "loss: 162.67111755907536\n",
      "accuracy (train): 0.914275033070685\n",
      "accuracy (validation): 0.9006417602567041\n",
      "Epoch 10:\n",
      "loss: 157.17851378768682\n",
      "accuracy (train): 0.9172370161615\n",
      "accuracy (validation): 0.906257162502865\n",
      "Epoch 11:\n",
      "loss: 78.21120119839907\n",
      "accuracy (train): 0.9566342669810778\n",
      "accuracy (validation): 0.9390327756131103\n",
      "Epoch 12:\n",
      "loss: 86.99468142166734\n",
      "accuracy (train): 0.9537585552424225\n",
      "accuracy (validation): 0.9210405684162274\n",
      "Epoch 13:\n",
      "loss: 88.2272639349103\n",
      "accuracy (train): 0.9569793523897164\n",
      "accuracy (validation): 0.9492321796928719\n",
      "Epoch 14:\n",
      "loss: 89.09401609376073\n",
      "accuracy (train): 0.956691781215851\n",
      "accuracy (validation): 0.9431583772633509\n",
      "Epoch 15:\n",
      "loss: 82.21652245521545\n",
      "accuracy (train): 0.9612354057629263\n",
      "accuracy (validation): 0.962640385056154\n",
      "Epoch 16:\n",
      "loss: 79.20555077120662\n",
      "accuracy (train): 0.9621843906366826\n",
      "accuracy (validation): 0.9509511803804721\n",
      "Epoch 17:\n",
      "loss: 82.08211484923959\n",
      "accuracy (train): 0.9625869902800943\n",
      "accuracy (validation): 0.9518679807471923\n",
      "Epoch 18:\n",
      "loss: 74.3425755687058\n",
      "accuracy (train): 0.9654051877839765\n",
      "accuracy (validation): 0.962411184964474\n",
      "Epoch 19:\n",
      "loss: 74.19134757295251\n",
      "accuracy (train): 0.9669580721228505\n",
      "accuracy (validation): 0.9644739857895943\n",
      "Epoch 20:\n",
      "loss: 71.36752600222826\n",
      "accuracy (train): 0.9688272847529764\n",
      "accuracy (validation): 0.9600045840018336\n",
      "Epoch 21:\n",
      "loss: 36.198262984864414\n",
      "accuracy (train): 0.9837522286765975\n",
      "accuracy (validation): 0.9767361906944763\n",
      "Epoch 22:\n",
      "loss: 37.400232423096895\n",
      "accuracy (train): 0.9844136423764882\n",
      "accuracy (validation): 0.9783405913362365\n",
      "Epoch 23:\n",
      "loss: 40.13421160541475\n",
      "accuracy (train): 0.9850175418416058\n",
      "accuracy (validation): 0.9716937886775154\n",
      "Epoch 24:\n",
      "loss: 40.35072284005582\n",
      "accuracy (train): 0.9859090124805889\n",
      "accuracy (validation): 0.9718083887233555\n",
      "Epoch 25:\n",
      "loss: 44.38329306803644\n",
      "accuracy (train): 0.984039799850463\n",
      "accuracy (validation): 0.9590877836351135\n",
      "Epoch 26:\n",
      "loss: 40.05686294287443\n",
      "accuracy (train): 0.9856214413067235\n",
      "accuracy (validation): 0.9742149896859958\n",
      "Epoch 27:\n",
      "loss: 41.879413831979036\n",
      "accuracy (train): 0.9853051130154713\n",
      "accuracy (validation): 0.9713499885399954\n",
      "Epoch 28:\n",
      "loss: 36.715622674673796\n",
      "accuracy (train): 0.9873181112325301\n",
      "accuracy (validation): 0.9778821911528764\n",
      "Epoch 29:\n",
      "loss: 37.0936884842813\n",
      "accuracy (train): 0.9879507678150342\n",
      "accuracy (validation): 0.9720375888150355\n",
      "Epoch 30:\n",
      "loss: 41.48085748590529\n",
      "accuracy (train): 0.9855351699545638\n",
      "accuracy (validation): 0.9771945908778363\n",
      "Epoch 31:\n",
      "loss: 18.204570470377803\n",
      "accuracy (train): 0.9950250186921263\n",
      "accuracy (validation): 0.9814347925739171\n",
      "Epoch 32:\n",
      "loss: 17.63665847107768\n",
      "accuracy (train): 0.996204060504975\n",
      "accuracy (validation): 0.9796011918404768\n",
      "Epoch 33:\n",
      "loss: 18.920419883914292\n",
      "accuracy (train): 0.9961753033875884\n",
      "accuracy (validation): 0.9787989915195966\n",
      "Epoch 34:\n",
      "loss: 20.67152203246951\n",
      "accuracy (train): 0.9957727037441767\n",
      "accuracy (validation): 0.9766215906486363\n",
      "Epoch 35:\n",
      "loss: 23.10430755559355\n",
      "accuracy (train): 0.995370104100765\n",
      "accuracy (validation): 0.9799449919779968\n",
      "Epoch 36:\n",
      "loss: 22.89284884929657\n",
      "accuracy (train): 0.9953125898659918\n",
      "accuracy (validation): 0.9802887921155169\n",
      "Epoch 37:\n",
      "loss: 18.977622100152075\n",
      "accuracy (train): 0.9966354172657733\n",
      "accuracy (validation): 0.9792573917029567\n",
      "Epoch 38:\n",
      "loss: 20.565230695530772\n",
      "accuracy (train): 0.9961177891528153\n",
      "accuracy (validation): 0.9703185881274352\n",
      "Epoch 39:\n",
      "loss: 27.76029765792191\n",
      "accuracy (train): 0.9939897624662104\n",
      "accuracy (validation): 0.9798303919321568\n",
      "Epoch 40:\n",
      "loss: 21.011259355582297\n",
      "accuracy (train): 0.9957727037441767\n",
      "accuracy (validation): 0.9834975933990373\n",
      "Epoch 41:\n",
      "loss: 10.697165293619037\n",
      "accuracy (train): 0.9993098291827227\n",
      "accuracy (validation): 0.9849873939949576\n",
      "Epoch 42:\n",
      "loss: 10.032173638232052\n",
      "accuracy (train): 0.999683671708748\n",
      "accuracy (validation): 0.9839559935823974\n",
      "Epoch 43:\n",
      "loss: 10.680798285640776\n",
      "accuracy (train): 0.9999712428826134\n",
      "accuracy (validation): 0.9842997937199175\n",
      "Epoch 44:\n",
      "loss: 14.59493231959641\n",
      "accuracy (train): 0.9987346868349917\n",
      "accuracy (validation): 0.9840705936282375\n",
      "Epoch 45:\n",
      "loss: 16.447209461592138\n",
      "accuracy (train): 0.997871973313395\n",
      "accuracy (validation): 0.9786843914737566\n",
      "Epoch 46:\n",
      "loss: 13.669639040715992\n",
      "accuracy (train): 0.9990222580088572\n",
      "accuracy (validation): 0.9847581939032776\n",
      "Epoch 47:\n",
      "loss: 11.853578751906753\n",
      "accuracy (train): 0.9996549145913614\n",
      "accuracy (validation): 0.9842997937199175\n",
      "Epoch 48:\n",
      "loss: 15.868731030263007\n",
      "accuracy (train): 0.9984471156611261\n",
      "accuracy (validation): 0.9796011918404768\n",
      "Epoch 49:\n",
      "loss: 17.113710014149547\n",
      "accuracy (train): 0.9977281877264623\n",
      "accuracy (validation): 0.9802887921155169\n",
      "Epoch 50:\n",
      "loss: 12.99005130212754\n",
      "accuracy (train): 0.9991372864784034\n",
      "accuracy (validation): 0.9830391932156772\n",
      "task2 model saved\n"
     ]
    }
   ],
   "source": [
    "model = ResNet34_2(ResidualBlock).to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "totalEpoch = 50\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=6.5e-4)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "#optimizer = torch.optim.NAdam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=6.5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(totalEpoch):\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    total_loss = 0\n",
    "    train_sample_count = 0\n",
    "    train_correct_count = 0\n",
    "    model.train()\n",
    "    for image, label in train_dl:\n",
    "        image = image.to(device)\n",
    "        \n",
    "        # csv file will ignore string start with 0, need to deal with it.\n",
    "        tmp = []\n",
    "        for i in range(len(label)):\n",
    "            if len(label[i]) == 1:\n",
    "                tmp.append(\"0\" + label[i][0])\n",
    "            else:\n",
    "                tmp.append(label[i])\n",
    "        \n",
    "        label = tmp\n",
    "        \n",
    "        label_1 = np.array([alphabets2index[l[0]] for l in label])\n",
    "        label_1 = torch.from_numpy(label_1)\n",
    "        label_1 = label_1.to(device, dtype=torch.long)\n",
    "        label_2 = np.array([alphabets2index[l[1]] for l in label])\n",
    "        label_2 = torch.from_numpy(label_2)\n",
    "        label_2 = label_2.to(device, dtype=torch.long)\n",
    "        \n",
    "        pred_1, pred_2 = model(image)\n",
    "        loss1 = loss_fn(pred_1, label_1)\n",
    "        loss2 = loss_fn(pred_2, label_2)\n",
    "        loss = loss1 + loss2\n",
    "        total_loss += loss.item()\n",
    "        pred_1 = torch.argmax(pred_1, dim=1)\n",
    "        pred_2 = torch.argmax(pred_2, dim=1)\n",
    "        \n",
    "        train_sample_count += len(image)\n",
    "        \n",
    "        for i in range(len(label_1)):\n",
    "            if (label_1[i] == pred_1[i]) and (label_2[i] == pred_2[i]):\n",
    "                train_correct_count += 1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "        \n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    model.eval()\n",
    "    for image, label in val_dl:\n",
    "        image = image.to(device)\n",
    "        \n",
    "        tmp = []\n",
    "        for i in range(len(label)):\n",
    "            if len(label[i]) == 1:\n",
    "                tmp.append(\"0\" + label[i][0])\n",
    "            else:\n",
    "                tmp.append(label[i])\n",
    "        \n",
    "        label = tmp\n",
    "        \n",
    "        label_1 = np.array([alphabets2index[l[0]] for l in label])\n",
    "        label_1 = torch.from_numpy(label_1)\n",
    "        label_1 = label_1.to(device, dtype=torch.long)\n",
    "        label_2 = np.array([alphabets2index[l[1]] for l in label])\n",
    "        label_2 = torch.from_numpy(label_2)\n",
    "        label_2 = label_2.to(device, dtype=torch.long)\n",
    "        \n",
    "        pred_1, pred_2 = model(image)\n",
    "        \n",
    "        pred_1 = torch.argmax(pred_1, dim=1)\n",
    "        pred_2 = torch.argmax(pred_2, dim=1)\n",
    "        \n",
    "        sample_count += len(image)\n",
    "        \n",
    "        for i in range(len(label_1)):\n",
    "            if (label_1[i] == pred_1[i]) and (label_2[i] == pred_2[i]):\n",
    "                correct_count += 1\n",
    "    \n",
    "    print(\"loss:\", total_loss)\n",
    "    print(\"accuracy (train):\", train_correct_count / train_sample_count)\n",
    "    print(\"accuracy (validation):\", correct_count / sample_count)\n",
    "\n",
    "torch.save(model.state_dict(), 'models/task2.pt')\n",
    "print('task2 model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab6958",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d36e7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "train_ds = TaskDataset(train_data_t3, root=TRAIN_PATH)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "val_ds = TaskDataset(val_data_t3, root=TRAIN_PATH)\n",
    "val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfb4f3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "loss: 15233.403171539307\n",
      "accuracy (train): 0.0\n",
      "accuracy (validation): 0.0\n",
      "Epoch 2:\n",
      "loss: 11428.269597530365\n",
      "accuracy (train): 0.017932278100581046\n",
      "accuracy (validation): 0.18640699523052465\n",
      "Epoch 3:\n",
      "loss: 2637.840287208557\n",
      "accuracy (train): 0.4230949041608228\n",
      "accuracy (validation): 0.7082008479067302\n",
      "Epoch 4:\n",
      "loss: 1232.0390899181366\n",
      "accuracy (train): 0.6799572563948441\n",
      "accuracy (validation): 0.7215156332803392\n",
      "Epoch 5:\n",
      "loss: 909.5706135034561\n",
      "accuracy (train): 0.7597842783677285\n",
      "accuracy (validation): 0.8436009538950715\n",
      "Epoch 6:\n",
      "loss: 752.7179427742958\n",
      "accuracy (train): 0.8002738262205303\n",
      "accuracy (validation): 0.8533386327503975\n",
      "Epoch 7:\n",
      "loss: 661.1449235379696\n",
      "accuracy (train): 0.8245675549322113\n",
      "accuracy (validation): 0.8771860095389508\n",
      "Epoch 8:\n",
      "loss: 593.718759894371\n",
      "accuracy (train): 0.8418820543645228\n",
      "accuracy (validation): 0.8991123476417594\n",
      "Epoch 9:\n",
      "loss: 562.4475064873695\n",
      "accuracy (train): 0.8513490950377346\n",
      "accuracy (validation): 0.8856650768415474\n",
      "Epoch 10:\n",
      "loss: 511.3051825761795\n",
      "accuracy (train): 0.8645395044413278\n",
      "accuracy (validation): 0.840818759936407\n",
      "Epoch 11:\n",
      "loss: 499.943685233593\n",
      "accuracy (train): 0.8700160288519335\n",
      "accuracy (validation): 0.8441971383147854\n",
      "Epoch 12:\n",
      "loss: 486.98682306706905\n",
      "accuracy (train): 0.8729379549856409\n",
      "accuracy (validation): 0.8583068362480127\n",
      "Epoch 13:\n",
      "loss: 462.9935863018036\n",
      "accuracy (train): 0.8792660121552127\n",
      "accuracy (validation): 0.9014970853206147\n",
      "Epoch 14:\n",
      "loss: 449.538091391325\n",
      "accuracy (train): 0.8835904628330996\n",
      "accuracy (validation): 0.9007684154742979\n",
      "Epoch 15:\n",
      "loss: 430.9854483753443\n",
      "accuracy (train): 0.8874474053295933\n",
      "accuracy (validation): 0.8685082140964494\n",
      "Epoch 16:\n",
      "loss: 247.60387638956308\n",
      "accuracy (train): 0.9332131169438322\n",
      "accuracy (validation): 0.9377980922098569\n",
      "Epoch 17:\n",
      "loss: 262.5231105610728\n",
      "accuracy (train): 0.9365858545381687\n",
      "accuracy (validation): 0.9088500264970854\n",
      "Epoch 18:\n",
      "loss: 276.4605185687542\n",
      "accuracy (train): 0.9353002070393375\n",
      "accuracy (validation): 0.9063328033916269\n",
      "Epoch 19:\n",
      "loss: 256.1687960103154\n",
      "accuracy (train): 0.9414112068389768\n",
      "accuracy (validation): 0.936075781664017\n",
      "Epoch 20:\n",
      "loss: 258.75244285166264\n",
      "accuracy (train): 0.9427636412208642\n",
      "accuracy (validation): 0.9370031796502385\n",
      "Epoch 21:\n",
      "loss: 252.31335394829512\n",
      "accuracy (train): 0.9433480264476057\n",
      "accuracy (validation): 0.935214626391097\n",
      "Epoch 22:\n",
      "loss: 253.49984163045883\n",
      "accuracy (train): 0.9451345755693582\n",
      "accuracy (validation): 0.9526364599894012\n",
      "Epoch 23:\n",
      "loss: 240.56267876178026\n",
      "accuracy (train): 0.9472049689440993\n",
      "accuracy (validation): 0.9382617912029677\n",
      "Epoch 24:\n",
      "loss: 255.84897397458553\n",
      "accuracy (train): 0.9453182394977626\n",
      "accuracy (validation): 0.9475357710651828\n",
      "Epoch 25:\n",
      "loss: 234.73211087286472\n",
      "accuracy (train): 0.950644493421492\n",
      "accuracy (validation): 0.9479332273449921\n",
      "Epoch 26:\n",
      "loss: 238.4625770226121\n",
      "accuracy (train): 0.9484071328391104\n",
      "accuracy (validation): 0.951377848436672\n",
      "Epoch 27:\n",
      "loss: 238.6884026452899\n",
      "accuracy (train): 0.9489247311827957\n",
      "accuracy (validation): 0.9468071012188659\n",
      "Epoch 28:\n",
      "loss: 230.70594934374094\n",
      "accuracy (train): 0.950644493421492\n",
      "accuracy (validation): 0.9510466348701643\n",
      "Epoch 29:\n",
      "loss: 238.14040724933147\n",
      "accuracy (train): 0.951011821278301\n",
      "accuracy (validation): 0.9399841017488076\n",
      "Epoch 30:\n",
      "loss: 228.37647269666195\n",
      "accuracy (train): 0.9516629933880986\n",
      "accuracy (validation): 0.9536301006889242\n",
      "Epoch 31:\n",
      "loss: 124.6209731027484\n",
      "accuracy (train): 0.9759734188205437\n",
      "accuracy (validation): 0.9646926338102809\n",
      "Epoch 32:\n",
      "loss: 132.08858041465282\n",
      "accuracy (train): 0.9775930007346557\n",
      "accuracy (validation): 0.9664149443561209\n",
      "Epoch 33:\n",
      "loss: 135.2202142253518\n",
      "accuracy (train): 0.9782942630067455\n",
      "accuracy (validation): 0.9574721780604134\n",
      "Epoch 34:\n",
      "loss: 145.17684572190046\n",
      "accuracy (train): 0.9768583450210379\n",
      "accuracy (validation): 0.9664149443561209\n",
      "Epoch 35:\n",
      "loss: 135.8886694125831\n",
      "accuracy (train): 0.9780104187537567\n",
      "accuracy (validation): 0.9621754107048225\n",
      "Epoch 36:\n",
      "loss: 136.29799079149961\n",
      "accuracy (train): 0.9787617711881387\n",
      "accuracy (validation): 0.9620429252782194\n",
      "Epoch 37:\n",
      "loss: 143.6716055124998\n",
      "accuracy (train): 0.9772590663193749\n",
      "accuracy (validation): 0.9570084790673026\n",
      "Epoch 38:\n",
      "loss: 130.124603420496\n",
      "accuracy (train): 0.9797301809924531\n",
      "accuracy (validation): 0.9525702172760996\n",
      "Epoch 39:\n",
      "loss: 132.8634086996317\n",
      "accuracy (train): 0.9810325252120483\n",
      "accuracy (validation): 0.960519342872284\n",
      "Epoch 40:\n",
      "loss: 126.9382106512785\n",
      "accuracy (train): 0.9817170907633741\n",
      "accuracy (validation): 0.9599231584525703\n",
      "Epoch 41:\n",
      "loss: 141.7637240588665\n",
      "accuracy (train): 0.9790289187203634\n",
      "accuracy (validation): 0.9588632750397457\n",
      "Epoch 42:\n",
      "loss: 137.21922863647342\n",
      "accuracy (train): 0.9799138449208575\n",
      "accuracy (validation): 0.9641626921038686\n",
      "Epoch 43:\n",
      "loss: 119.53893147781491\n",
      "accuracy (train): 0.9841047218326321\n",
      "accuracy (validation): 0.9678722840487546\n",
      "Epoch 44:\n",
      "loss: 136.0875965282321\n",
      "accuracy (train): 0.9802477793361384\n",
      "accuracy (validation): 0.9578033916269211\n",
      "Epoch 45:\n",
      "loss: 118.52725787460804\n",
      "accuracy (train): 0.9847225005009016\n",
      "accuracy (validation): 0.960519342872284\n",
      "Epoch 46:\n",
      "loss: 73.04556809738278\n",
      "accuracy (train): 0.9931376477659788\n",
      "accuracy (validation): 0.9701245363010069\n",
      "Epoch 47:\n",
      "loss: 70.5335341989994\n",
      "accuracy (train): 0.9952581313030121\n",
      "accuracy (validation): 0.9662824589295178\n",
      "Epoch 48:\n",
      "loss: 83.53240459412336\n",
      "accuracy (train): 0.993605155947372\n",
      "accuracy (validation): 0.9670111287758346\n",
      "Epoch 49:\n",
      "loss: 84.38131761923432\n",
      "accuracy (train): 0.9933547051359113\n",
      "accuracy (validation): 0.9679385267620562\n",
      "Epoch 50:\n",
      "loss: 83.01317809149623\n",
      "accuracy (train): 0.9933714018566754\n",
      "accuracy (validation): 0.9710519342872284\n",
      "Epoch 51:\n",
      "loss: 84.47870060056448\n",
      "accuracy (train): 0.9935216723435517\n",
      "accuracy (validation): 0.9656200317965024\n",
      "Epoch 52:\n",
      "loss: 83.92093089967966\n",
      "accuracy (train): 0.9930040739998665\n",
      "accuracy (validation): 0.9668786433492316\n",
      "Epoch 53:\n",
      "loss: 76.65010439231992\n",
      "accuracy (train): 0.9949408936084952\n",
      "accuracy (validation): 0.9591944886062533\n",
      "Epoch 54:\n",
      "loss: 84.8634589985013\n",
      "accuracy (train): 0.9933547051359113\n",
      "accuracy (validation): 0.9590620031796503\n",
      "Epoch 55:\n",
      "loss: 78.3735172264278\n",
      "accuracy (train): 0.9949909837707874\n",
      "accuracy (validation): 0.966679915209327\n",
      "Epoch 56:\n",
      "loss: 88.9259121157229\n",
      "accuracy (train): 0.9929873772791024\n",
      "accuracy (validation): 0.9667461579226285\n",
      "Epoch 57:\n",
      "loss: 75.90293836221099\n",
      "accuracy (train): 0.9946403526347425\n",
      "accuracy (validation): 0.9613142554319025\n",
      "Epoch 58:\n",
      "loss: 80.31015355885029\n",
      "accuracy (train): 0.9945568690309223\n",
      "accuracy (validation): 0.9651563328033916\n",
      "Epoch 59:\n",
      "loss: 84.1569977812469\n",
      "accuracy (train): 0.994005877245709\n",
      "accuracy (validation): 0.9672098569157392\n",
      "Epoch 60:\n",
      "loss: 84.34681052342057\n",
      "accuracy (train): 0.9935216723435517\n",
      "accuracy (validation): 0.9669448860625331\n",
      "Epoch 61:\n",
      "loss: 52.27502872236073\n",
      "accuracy (train): 0.9983971148066519\n",
      "accuracy (validation): 0.9707207207207207\n",
      "Epoch 62:\n",
      "loss: 52.284687547013164\n",
      "accuracy (train): 0.9989314098711013\n",
      "accuracy (validation): 0.9697933227344993\n",
      "Epoch 63:\n",
      "loss: 55.97640550509095\n",
      "accuracy (train): 0.9990482869164496\n",
      "accuracy (validation): 0.9694621091679915\n",
      "Epoch 64:\n",
      "loss: 65.80359084904194\n",
      "accuracy (train): 0.9972450410739331\n",
      "accuracy (validation): 0.9697270800211977\n",
      "Epoch 65:\n",
      "loss: 58.922138158231974\n",
      "accuracy (train): 0.9985640820142924\n",
      "accuracy (validation): 0.9705882352941176\n",
      "Epoch 66:\n",
      "loss: 62.0677740983665\n",
      "accuracy (train): 0.9977793361383824\n",
      "accuracy (validation): 0.9709856915739269\n",
      "Epoch 67:\n",
      "loss: 58.62627065554261\n",
      "accuracy (train): 0.9984639016897081\n",
      "accuracy (validation): 0.9710519342872284\n",
      "Epoch 68:\n",
      "loss: 62.29355286806822\n",
      "accuracy (train): 0.9983136312028318\n",
      "accuracy (validation): 0.9713831478537361\n",
      "Epoch 69:\n",
      "loss: 63.370221976190805\n",
      "accuracy (train): 0.9978962131837307\n",
      "accuracy (validation): 0.9664149443561209\n",
      "Epoch 70:\n",
      "loss: 61.806074660271406\n",
      "accuracy (train): 0.9982134508782475\n",
      "accuracy (validation): 0.9713169051404346\n",
      "Epoch 71:\n",
      "loss: 60.767764177173376\n",
      "accuracy (train): 0.9981800574367194\n",
      "accuracy (validation): 0.972972972972973\n",
      "Epoch 72:\n",
      "loss: 64.07226993888617\n",
      "accuracy (train): 0.997629065651506\n",
      "accuracy (validation): 0.97025702172761\n",
      "Epoch 73:\n",
      "loss: 58.477673234418035\n",
      "accuracy (train): 0.9985807787350565\n",
      "accuracy (validation): 0.9746290408055114\n",
      "Epoch 74:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 63.85357578098774\n",
      "accuracy (train): 0.9977459426968543\n",
      "accuracy (validation): 0.9726417594064652\n",
      "Epoch 75:\n",
      "loss: 62.062156330794096\n",
      "accuracy (train): 0.9977960328591464\n",
      "accuracy (validation): 0.9699920508744038\n",
      "task3 model saved\n"
     ]
    }
   ],
   "source": [
    "model = ResNet34_3(ResidualBlock).to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "totalEpoch = 75\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=6.5e-4)\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "#optimizer = torch.optim.NAdam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=6.5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(totalEpoch):\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    total_loss = 0\n",
    "    train_sample_count = 0\n",
    "    train_correct_count = 0\n",
    "    model.train()\n",
    "    for image, label in train_dl:\n",
    "        # csv file will ignore string start with 0, need to deal with it.\n",
    "        tmp = []\n",
    "        for i in range(len(label)):\n",
    "            if len(label[i]) == 3:\n",
    "                tmp.append(\"0\" + label[i][0])\n",
    "            else:\n",
    "                tmp.append(label[i])\n",
    "        \n",
    "        label = tmp\n",
    "        \n",
    "        label_1 = []\n",
    "        label_2 = []\n",
    "        label_3 = []\n",
    "        label_4 = []\n",
    "        error_index = []\n",
    "        for i in range(len(label)):\n",
    "            try:\n",
    "                letter1 = alphabets2index[label[i][0]]\n",
    "                letter2 = alphabets2index[label[i][1]]\n",
    "                letter3 = alphabets2index[label[i][2]]\n",
    "                letter4 = alphabets2index[label[i][3]]\n",
    "            except:\n",
    "                error_index.append(i)\n",
    "            else:\n",
    "                label_1.append(letter1)\n",
    "                label_2.append(letter2)\n",
    "                label_3.append(letter3)\n",
    "                label_4.append(letter4)\n",
    "        \n",
    "        label_1 = np.array(label_1)\n",
    "        label_1 = torch.from_numpy(label_1)\n",
    "        label_1 = label_1.to(device, dtype=torch.long)\n",
    "        label_2 = np.array(label_2)\n",
    "        label_2 = torch.from_numpy(label_2)\n",
    "        label_2 = label_2.to(device, dtype=torch.long)\n",
    "        label_3 = np.array(label_3)\n",
    "        label_3 = torch.from_numpy(label_3)\n",
    "        label_3 = label_3.to(device, dtype=torch.long)\n",
    "        label_4 = np.array(label_4)\n",
    "        label_4 = torch.from_numpy(label_4)\n",
    "        label_4 = label_4.to(device, dtype=torch.long)\n",
    "                \n",
    "        \n",
    "        #label_1 = np.array([alphabets2index[l[0]] for l in label])\n",
    "        #label_1 = torch.from_numpy(label_1)\n",
    "        #label_1 = label_1.to(device, dtype=torch.long)\n",
    "        #label_2 = np.array([alphabets2index[l[1]] for l in label])\n",
    "        #label_2 = torch.from_numpy(label_2)\n",
    "        #label_2 = label_2.to(device, dtype=torch.long)\n",
    "        #label_3 = np.array([alphabets2index[l[2]] for l in label])\n",
    "        #label_3 = torch.from_numpy(label_3)\n",
    "        #label_3 = label_3.to(device, dtype=torch.long)\n",
    "        #label_4 = np.array([alphabets2index[l[3]] for l in label])\n",
    "        #label_4 = torch.from_numpy(label_4)\n",
    "        #label_4 = label_4.to(device, dtype=torch.long)\n",
    "        \n",
    "        image = image.cpu().numpy()\n",
    "        image_buffer = []\n",
    "        for i in range(len(image)):\n",
    "            if i not in error_index:\n",
    "                image_buffer.append(image[i])\n",
    "        \n",
    "        image_buffer = np.array(image_buffer)\n",
    "        image = torch.from_numpy(image_buffer)\n",
    "        image = image.to(device)\n",
    "        \n",
    "        pred_1, pred_2, pred_3, pred_4 = model(image)\n",
    "        loss1 = loss_fn(pred_1, label_1)\n",
    "        loss2 = loss_fn(pred_2, label_2)\n",
    "        loss3 = loss_fn(pred_3, label_3)\n",
    "        loss4 = loss_fn(pred_4, label_4)\n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        total_loss += loss.item()\n",
    "        pred_1 = torch.argmax(pred_1, dim=1)\n",
    "        pred_2 = torch.argmax(pred_2, dim=1)\n",
    "        pred_3 = torch.argmax(pred_3, dim=1)\n",
    "        pred_4 = torch.argmax(pred_4, dim=1)\n",
    "        \n",
    "        train_sample_count += len(image)\n",
    "        \n",
    "        for i in range(len(label_1)):\n",
    "            if (label_1[i] == pred_1[i]) and (label_2[i] == pred_2[i]) and (label_3[i] == pred_3[i]) and (label_4[i] == pred_4[i]):\n",
    "                train_correct_count += 1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "        \n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    model.eval()\n",
    "    for image, label in val_dl:\n",
    "        # csv file will ignore string start with 0, need to deal with it.\n",
    "        tmp = []\n",
    "        for i in range(len(label)):\n",
    "            if len(label[i]) == 3:\n",
    "                tmp.append(\"0\" + label[i][0])\n",
    "            else:\n",
    "                tmp.append(label[i])\n",
    "        \n",
    "        label = tmp\n",
    "        \n",
    "        label_1 = []\n",
    "        label_2 = []\n",
    "        label_3 = []\n",
    "        label_4 = []\n",
    "        error_index = []\n",
    "        for i in range(len(label)):\n",
    "            try:\n",
    "                letter1 = alphabets2index[label[i][0]]\n",
    "                letter2 = alphabets2index[label[i][1]]\n",
    "                letter3 = alphabets2index[label[i][2]]\n",
    "                letter4 = alphabets2index[label[i][3]]\n",
    "            except:\n",
    "                error_index.append(i)\n",
    "            else:\n",
    "                label_1.append(letter1)\n",
    "                label_2.append(letter2)\n",
    "                label_3.append(letter3)\n",
    "                label_4.append(letter4)\n",
    "        \n",
    "        label_1 = np.array(label_1)\n",
    "        label_1 = torch.from_numpy(label_1)\n",
    "        label_1 = label_1.to(device, dtype=torch.long)\n",
    "        label_2 = np.array(label_2)\n",
    "        label_2 = torch.from_numpy(label_2)\n",
    "        label_2 = label_2.to(device, dtype=torch.long)\n",
    "        label_3 = np.array(label_3)\n",
    "        label_3 = torch.from_numpy(label_3)\n",
    "        label_3 = label_3.to(device, dtype=torch.long)\n",
    "        label_4 = np.array(label_4)\n",
    "        label_4 = torch.from_numpy(label_4)\n",
    "        label_4 = label_4.to(device, dtype=torch.long)\n",
    "                \n",
    "        \n",
    "        #label_1 = np.array([alphabets2index[l[0]] for l in label])\n",
    "        #label_1 = torch.from_numpy(label_1)\n",
    "        #label_1 = label_1.to(device, dtype=torch.long)\n",
    "        #label_2 = np.array([alphabets2index[l[1]] for l in label])\n",
    "        #label_2 = torch.from_numpy(label_2)\n",
    "        #label_2 = label_2.to(device, dtype=torch.long)\n",
    "        #label_3 = np.array([alphabets2index[l[2]] for l in label])\n",
    "        #label_3 = torch.from_numpy(label_3)\n",
    "        #label_3 = label_3.to(device, dtype=torch.long)\n",
    "        #label_4 = np.array([alphabets2index[l[3]] for l in label])\n",
    "        #label_4 = torch.from_numpy(label_4)\n",
    "        #label_4 = label_4.to(device, dtype=torch.long)\n",
    "        \n",
    "        image = image.cpu().numpy()\n",
    "        image_buffer = []\n",
    "        for i in range(len(image)):\n",
    "            if i not in error_index:\n",
    "                image_buffer.append(image[i])\n",
    "        \n",
    "        image_buffer = np.array(image_buffer)\n",
    "        image = torch.from_numpy(image_buffer)\n",
    "        image = image.to(device)\n",
    "        \n",
    "        pred_1, pred_2, pred_3, pred_4 = model(image)\n",
    "        \n",
    "        pred_1 = torch.argmax(pred_1, dim=1)\n",
    "        pred_2 = torch.argmax(pred_2, dim=1)\n",
    "        pred_3 = torch.argmax(pred_3, dim=1)\n",
    "        pred_4 = torch.argmax(pred_4, dim=1)\n",
    "        \n",
    "        sample_count += len(image)\n",
    "        \n",
    "        for i in range(len(label_1)):\n",
    "            if (label_1[i] == pred_1[i]) and (label_2[i] == pred_2[i]) and (label_3[i] == pred_3[i]) and (label_4[i] == pred_4[i]):\n",
    "                correct_count += 1\n",
    "    \n",
    "    print(\"loss:\", total_loss)\n",
    "    print(\"accuracy (train):\", train_correct_count / train_sample_count)\n",
    "    print(\"accuracy (validation):\", correct_count / sample_count)\n",
    "\n",
    "torch.save(model.state_dict(), 'models/task3.pt')\n",
    "print('task3 model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6faba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 92.821945,
   "end_time": "2023-05-02T13:36:52.537973",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-02T13:35:19.716028",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
